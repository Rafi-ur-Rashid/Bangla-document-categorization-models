{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Text_classifier_CNN_word_embedding.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"jrmHuWQszBVF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"outputId":"0189a7a0-dc8c-44af-de3e-3328c57da65b","executionInfo":{"status":"ok","timestamp":1590271300980,"user_tz":-360,"elapsed":9882,"user":{"displayName":"Anonymous Learner","photoUrl":"","userId":"07578854066066276758"}}},"source":["import io\n","import keras\n","import tensorflow as tf\n","import os\n","import numpy as np # used for handling numbers\n","import pandas as pd # used for handling the dataset\n","df= pd.read_csv('drive/My Drive/Colab Notebooks/dataset/labeled_outs.txt',delimiter=\",\",header=None)\n","# Dataset is now stored in a Pandas Dataframe"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"9ONiKR_zpx9R","colab_type":"code","colab":{}},"source":["file = open('drive/My Drive/Colab Notebooks/dataset/vocab.txt', 'r')\n","# read all text\n","vocab = file.readlines()\n","vocabulary={}\n","for w in vocab:\n","  vocabulary[w.strip()]=\"a\"\n","# close the file\n","file.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4RO-zHTSBHpw","colab_type":"code","colab":{}},"source":["df.columns=['label','text']\n","df.text=df.text.astype(str)\n","df.label=df.label.astype(str)\n","df=df.sample(frac=1)\n","docs=df['text'].values\n","labels=df['label'].values"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fQ-I-ShX1Jky","colab_type":"code","colab":{}},"source":["docs_filtered=[]\n","for d in docs:\n","  # split into tokens by white space\n","  tokens = d.split()\n","  temp=\"\"\n","  for t in tokens:\n","    if t in vocabulary:\n","      temp=temp+\" \"+t\n","  docs_filtered.append(temp)\n","  \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CGlwd8GMSs1p","colab_type":"code","colab":{}},"source":["# integer encode the documents\n","from keras.preprocessing.text import one_hot\n","vocab_size = len(vocabulary)+1\n","\n","encoded_docs = [one_hot(d, vocab_size) for d in docs_filtered]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nA3gwLvMW3KM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"outputId":"a393cfdb-39f7-4c30-f0ad-11123d0107b4","executionInfo":{"status":"ok","timestamp":1590271340406,"user_tz":-360,"elapsed":39023,"user":{"displayName":"Anonymous Learner","photoUrl":"","userId":"07578854066066276758"}}},"source":["# pad documents to a max length of 4 words\n","max_length = 200\n","padded_docs = keras.preprocessing.sequence.pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n","print(len(padded_docs))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["91795\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MWSLyHOec88f","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"outputId":"199b6617-50dc-4737-9f17-c231de1088be","executionInfo":{"status":"ok","timestamp":1590271340930,"user_tz":-360,"elapsed":36943,"user":{"displayName":"Anonymous Learner","photoUrl":"","userId":"07578854066066276758"}}},"source":["#import sys\n","#import numpy\n","#numpy.set_printoptions(threshold=sys.maxsize)\n","from keras.utils import np_utils\n","from sklearn.preprocessing import LabelEncoder\n","# encode class values as integers\n","encoder = LabelEncoder()\n","encoder.fit(labels)\n","encoded_Y = encoder.transform(labels)\n","# convert integers to dummy variables (i.e. one hot encoded)\n","dummy_y = np_utils.to_categorical(encoded_Y)\n","print(dummy_y.shape)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["(91795, 8)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OnEbb06DjZNa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":368},"outputId":"9ad4c4ae-ead2-49da-9ed0-85bc2b283f7c","executionInfo":{"status":"ok","timestamp":1590271352194,"user_tz":-360,"elapsed":11256,"user":{"displayName":"Anonymous Learner","photoUrl":"","userId":"07578854066066276758"}}},"source":["emb_dim=32\n","emb_model = tf.keras.Sequential([ \n","    tf.keras.layers.Input(shape=(max_length,)) ,                           \n","    tf.keras.layers.Embedding(vocab_size, output_dim=emb_dim),\n","    tf.keras.layers.GRU(128,return_sequences=True,dropout=0.3),\n","    tf.keras.layers.GRU(64,return_sequences=True,dropout=0.3),\n","    tf.keras.layers.GRU(32,return_sequences=True,dropout=0.3),\n","    tf.keras.layers.GRU(16),\n","    tf.keras.layers.Dense(8, activation=\"softmax\")\n","])\n","\n","emb_model.compile(optimizer='adam',loss= 'categorical_crossentropy',metrics=['acc'])\n","print(emb_model.summary())"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, 200, 32)           8000032   \n","_________________________________________________________________\n","gru (GRU)                    (None, 200, 128)          62208     \n","_________________________________________________________________\n","gru_1 (GRU)                  (None, 200, 64)           37248     \n","_________________________________________________________________\n","gru_2 (GRU)                  (None, 200, 32)           9408      \n","_________________________________________________________________\n","gru_3 (GRU)                  (None, 16)                2400      \n","_________________________________________________________________\n","dense (Dense)                (None, 8)                 136       \n","=================================================================\n","Total params: 8,111,432\n","Trainable params: 8,111,432\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4GB9wV6oZtRg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"e7ee828f-19b0-45da-b86a-4a5052622e9c","executionInfo":{"status":"ok","timestamp":1590272241570,"user_tz":-360,"elapsed":900617,"user":{"displayName":"Anonymous Learner","photoUrl":"","userId":"07578854066066276758"}}},"source":["emb_model.fit(padded_docs, dummy_y,epochs=30,batch_size=256, verbose=1,validation_split=0.1)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","323/323 [==============================] - 31s 95ms/step - loss: 1.7817 - acc: 0.3056 - val_loss: 1.6652 - val_acc: 0.3524\n","Epoch 2/30\n","323/323 [==============================] - 29s 91ms/step - loss: 1.1340 - acc: 0.5890 - val_loss: 0.8225 - val_acc: 0.7331\n","Epoch 3/30\n","323/323 [==============================] - 29s 91ms/step - loss: 0.5318 - acc: 0.8371 - val_loss: 0.3941 - val_acc: 0.8903\n","Epoch 4/30\n","323/323 [==============================] - 29s 90ms/step - loss: 0.2427 - acc: 0.9364 - val_loss: 0.3205 - val_acc: 0.9087\n","Epoch 5/30\n","323/323 [==============================] - 29s 91ms/step - loss: 0.1459 - acc: 0.9636 - val_loss: 0.2978 - val_acc: 0.9176\n","Epoch 6/30\n","323/323 [==============================] - 29s 90ms/step - loss: 0.0978 - acc: 0.9764 - val_loss: 0.3324 - val_acc: 0.9117\n","Epoch 7/30\n","323/323 [==============================] - 29s 90ms/step - loss: 0.0693 - acc: 0.9840 - val_loss: 0.3226 - val_acc: 0.9192\n","Epoch 8/30\n","323/323 [==============================] - 29s 90ms/step - loss: 0.0526 - acc: 0.9881 - val_loss: 0.3440 - val_acc: 0.9160\n","Epoch 9/30\n","323/323 [==============================] - 29s 90ms/step - loss: 0.0416 - acc: 0.9903 - val_loss: 0.3556 - val_acc: 0.9172\n","Epoch 10/30\n","323/323 [==============================] - 29s 90ms/step - loss: 0.0345 - acc: 0.9922 - val_loss: 0.3732 - val_acc: 0.9175\n","Epoch 11/30\n","323/323 [==============================] - 29s 90ms/step - loss: 0.0298 - acc: 0.9927 - val_loss: 0.3881 - val_acc: 0.9117\n","Epoch 12/30\n","323/323 [==============================] - 29s 90ms/step - loss: 0.0263 - acc: 0.9935 - val_loss: 0.3713 - val_acc: 0.9209\n","Epoch 13/30\n","323/323 [==============================] - 29s 90ms/step - loss: 0.0215 - acc: 0.9947 - val_loss: 0.3894 - val_acc: 0.9205\n","Epoch 14/30\n","323/323 [==============================] - 29s 90ms/step - loss: 0.0204 - acc: 0.9948 - val_loss: 0.3826 - val_acc: 0.9200\n","Epoch 15/30\n","323/323 [==============================] - 29s 91ms/step - loss: 0.0170 - acc: 0.9957 - val_loss: 0.4049 - val_acc: 0.9205\n","Epoch 16/30\n","323/323 [==============================] - 29s 90ms/step - loss: 0.0137 - acc: 0.9968 - val_loss: 0.3966 - val_acc: 0.9208\n","Epoch 17/30\n","323/323 [==============================] - 29s 90ms/step - loss: 0.0129 - acc: 0.9967 - val_loss: 0.4204 - val_acc: 0.9194\n","Epoch 18/30\n","323/323 [==============================] - 29s 90ms/step - loss: 0.0138 - acc: 0.9962 - val_loss: 0.4101 - val_acc: 0.9195\n","Epoch 19/30\n","323/323 [==============================] - 29s 90ms/step - loss: 0.0119 - acc: 0.9969 - val_loss: 0.4126 - val_acc: 0.9231\n","Epoch 20/30\n","323/323 [==============================] - 29s 89ms/step - loss: 0.0089 - acc: 0.9975 - val_loss: 0.4182 - val_acc: 0.9222\n","Epoch 21/30\n","323/323 [==============================] - 29s 90ms/step - loss: 0.0091 - acc: 0.9974 - val_loss: 0.4273 - val_acc: 0.9192\n","Epoch 22/30\n","323/323 [==============================] - 29s 90ms/step - loss: 0.0079 - acc: 0.9980 - val_loss: 0.4402 - val_acc: 0.9210\n","Epoch 23/30\n","323/323 [==============================] - 29s 90ms/step - loss: 0.0096 - acc: 0.9972 - val_loss: 0.4359 - val_acc: 0.9224\n","Epoch 24/30\n","323/323 [==============================] - 29s 90ms/step - loss: 0.0066 - acc: 0.9981 - val_loss: 0.4734 - val_acc: 0.9172\n","Epoch 25/30\n","323/323 [==============================] - 29s 90ms/step - loss: 0.0073 - acc: 0.9980 - val_loss: 0.4730 - val_acc: 0.9176\n","Epoch 26/30\n","323/323 [==============================] - 29s 91ms/step - loss: 0.0064 - acc: 0.9982 - val_loss: 0.4441 - val_acc: 0.9220\n","Epoch 27/30\n","323/323 [==============================] - 29s 91ms/step - loss: 0.0059 - acc: 0.9984 - val_loss: 0.4507 - val_acc: 0.9216\n","Epoch 28/30\n","323/323 [==============================] - 29s 90ms/step - loss: 0.0061 - acc: 0.9983 - val_loss: 0.4490 - val_acc: 0.9218\n","Epoch 29/30\n","323/323 [==============================] - 29s 90ms/step - loss: 0.0047 - acc: 0.9989 - val_loss: 0.4899 - val_acc: 0.9168\n","Epoch 30/30\n","323/323 [==============================] - 29s 91ms/step - loss: 0.0065 - acc: 0.9982 - val_loss: 0.4483 - val_acc: 0.9191\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f64103fb780>"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"hmPTa4XJZ-O_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"outputId":"6b2d84e1-a248-42d5-d175-03854cb03901","executionInfo":{"status":"ok","timestamp":1590272348220,"user_tz":-360,"elapsed":29009,"user":{"displayName":"Anonymous Learner","photoUrl":"","userId":"07578854066066276758"}}},"source":["emb_model1 = tf.keras.Model(inputs=emb_model.inputs , outputs=emb_model.layers[3].output)\n","emb_X = emb_model1.predict(padded_docs)\n","print(emb_X.shape)\n","#emb_X=np.reshape(emb_X, (emb_X.shape[0],1,-1))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["(91795, 200, 32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZAU-QRXaaDmn","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(emb_X, dummy_y, test_size=0.18)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ja7kPI6rab5q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":84},"outputId":"b6c854e1-758f-41bd-9995-ef98282ca855","executionInfo":{"status":"ok","timestamp":1590272349142,"user_tz":-360,"elapsed":28226,"user":{"displayName":"Anonymous Learner","photoUrl":"","userId":"07578854066066276758"}}},"source":["print(X_train.shape)\n","print(y_train.shape)\n","print(X_test.shape)\n","print(y_test.shape)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["(75271, 200, 32)\n","(75271, 8)\n","(16524, 200, 32)\n","(16524, 8)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zANk6xdDanrp","colab_type":"code","colab":{}},"source":["\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout\n","from keras.layers import Conv1D, MaxPooling1D,GlobalAveragePooling1D"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OwOTRDrK2VKe","colab_type":"code","colab":{}},"source":["\n","model = Sequential()\n","model.add(Conv1D(filters=256, kernel_size=7,input_shape=(X_train.shape[1],X_train.shape[2]), activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(MaxPooling1D(pool_size=1))\n","model.add(Dropout(0.4))\n","model.add(Conv1D(filters=128, kernel_size=6, activation='relu'))\n","model.add(Dropout(0.3))\n","model.add(MaxPooling1D(pool_size=1))\n","model.add(Dropout(0.2))\n","model.add(Conv1D(filters=64, kernel_size=5, activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(MaxPooling1D(pool_size=1))\n","model.add(Dropout(0.1))\n","model.add(GlobalAveragePooling1D())\n","model.add(Dropout(0.1))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dense(8, activation='softmax'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rRTS_yp-9uxL","colab_type":"code","outputId":"aa5a71ea-9d83-414c-ff1c-b8c6b0b31020","executionInfo":{"status":"ok","timestamp":1590274267907,"user_tz":-360,"elapsed":1587,"user":{"displayName":"Anonymous Learner","photoUrl":"","userId":"07578854066066276758"}},"colab":{"base_uri":"https://localhost:8080/","height":702}},"source":["\n","model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=['acc'])\n","# summarize the model\n","print(model.summary())"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv1d_4 (Conv1D)            (None, 194, 256)          57600     \n","_________________________________________________________________\n","dropout_8 (Dropout)          (None, 194, 256)          0         \n","_________________________________________________________________\n","max_pooling1d_4 (MaxPooling1 (None, 194, 256)          0         \n","_________________________________________________________________\n","dropout_9 (Dropout)          (None, 194, 256)          0         \n","_________________________________________________________________\n","conv1d_5 (Conv1D)            (None, 189, 128)          196736    \n","_________________________________________________________________\n","dropout_10 (Dropout)         (None, 189, 128)          0         \n","_________________________________________________________________\n","max_pooling1d_5 (MaxPooling1 (None, 189, 128)          0         \n","_________________________________________________________________\n","dropout_11 (Dropout)         (None, 189, 128)          0         \n","_________________________________________________________________\n","conv1d_6 (Conv1D)            (None, 185, 64)           41024     \n","_________________________________________________________________\n","dropout_12 (Dropout)         (None, 185, 64)           0         \n","_________________________________________________________________\n","max_pooling1d_6 (MaxPooling1 (None, 185, 64)           0         \n","_________________________________________________________________\n","dropout_13 (Dropout)         (None, 185, 64)           0         \n","_________________________________________________________________\n","global_average_pooling1d_2 ( (None, 64)                0         \n","_________________________________________________________________\n","dropout_14 (Dropout)         (None, 64)                0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                4160      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 8)                 520       \n","=================================================================\n","Total params: 300,040\n","Trainable params: 300,040\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C6Y8Sbfn-f-f","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":870},"outputId":"092d0cb4-b4b2-4dde-e668-6289e5594ac4","executionInfo":{"status":"ok","timestamp":1590274687288,"user_tz":-360,"elapsed":414778,"user":{"displayName":"Anonymous Learner","photoUrl":"","userId":"07578854066066276758"}}},"source":["history = model.fit(X_train, y_train, epochs=25,shuffle=False, verbose=1,validation_split=0.1)\n","#model.save_weights('./checkpoints/text_classifier_rnn_tfidf')\n","!mkdir -p saved_model\n","model.save('saved_model/text_classifier_rnn_tfidf')"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Train on 67743 samples, validate on 7528 samples\n","Epoch 1/25\n","67743/67743 [==============================] - 17s 245us/step - loss: 0.0959 - acc: 0.9774 - val_loss: 0.0785 - val_acc: 0.9825\n","Epoch 2/25\n","67743/67743 [==============================] - 16s 241us/step - loss: 0.0740 - acc: 0.9831 - val_loss: 0.0864 - val_acc: 0.9826\n","Epoch 3/25\n","67743/67743 [==============================] - 16s 241us/step - loss: 0.0630 - acc: 0.9859 - val_loss: 0.0812 - val_acc: 0.9853\n","Epoch 4/25\n","67743/67743 [==============================] - 16s 240us/step - loss: 0.0520 - acc: 0.9889 - val_loss: 0.0692 - val_acc: 0.9875\n","Epoch 5/25\n","67743/67743 [==============================] - 16s 240us/step - loss: 0.0497 - acc: 0.9889 - val_loss: 0.0676 - val_acc: 0.9878\n","Epoch 6/25\n","67743/67743 [==============================] - 16s 240us/step - loss: 0.0499 - acc: 0.9892 - val_loss: 0.0721 - val_acc: 0.9865\n","Epoch 7/25\n","67743/67743 [==============================] - 16s 240us/step - loss: 0.0481 - acc: 0.9895 - val_loss: 0.0614 - val_acc: 0.9887\n","Epoch 8/25\n","67743/67743 [==============================] - 16s 240us/step - loss: 0.0459 - acc: 0.9898 - val_loss: 0.0660 - val_acc: 0.9882\n","Epoch 9/25\n","67743/67743 [==============================] - 16s 240us/step - loss: 0.0472 - acc: 0.9901 - val_loss: 0.0689 - val_acc: 0.9875\n","Epoch 10/25\n","67743/67743 [==============================] - 16s 240us/step - loss: 0.0457 - acc: 0.9900 - val_loss: 0.0681 - val_acc: 0.9884\n","Epoch 11/25\n","67743/67743 [==============================] - 16s 240us/step - loss: 0.0434 - acc: 0.9904 - val_loss: 0.0680 - val_acc: 0.9876\n","Epoch 12/25\n","67743/67743 [==============================] - 16s 243us/step - loss: 0.0420 - acc: 0.9905 - val_loss: 0.0740 - val_acc: 0.9874\n","Epoch 13/25\n","67743/67743 [==============================] - 17s 246us/step - loss: 0.0420 - acc: 0.9907 - val_loss: 0.0662 - val_acc: 0.9875\n","Epoch 14/25\n","67743/67743 [==============================] - 16s 240us/step - loss: 0.0431 - acc: 0.9906 - val_loss: 0.0710 - val_acc: 0.9883\n","Epoch 15/25\n","67743/67743 [==============================] - 16s 240us/step - loss: 0.0414 - acc: 0.9908 - val_loss: 0.0678 - val_acc: 0.9887\n","Epoch 16/25\n","67743/67743 [==============================] - 16s 240us/step - loss: 0.0419 - acc: 0.9910 - val_loss: 0.0766 - val_acc: 0.9862\n","Epoch 17/25\n","67743/67743 [==============================] - 17s 246us/step - loss: 0.0408 - acc: 0.9907 - val_loss: 0.0736 - val_acc: 0.9870\n","Epoch 18/25\n","67743/67743 [==============================] - 16s 241us/step - loss: 0.0402 - acc: 0.9909 - val_loss: 0.0808 - val_acc: 0.9871\n","Epoch 19/25\n","67743/67743 [==============================] - 16s 242us/step - loss: 0.0406 - acc: 0.9907 - val_loss: 0.0863 - val_acc: 0.9865\n","Epoch 20/25\n","67743/67743 [==============================] - 16s 241us/step - loss: 0.0397 - acc: 0.9911 - val_loss: 0.0786 - val_acc: 0.9841\n","Epoch 21/25\n","67743/67743 [==============================] - 16s 243us/step - loss: 0.0399 - acc: 0.9914 - val_loss: 0.0830 - val_acc: 0.9861\n","Epoch 22/25\n","67743/67743 [==============================] - 16s 242us/step - loss: 0.0388 - acc: 0.9912 - val_loss: 0.0772 - val_acc: 0.9878\n","Epoch 23/25\n","67743/67743 [==============================] - 16s 242us/step - loss: 0.0376 - acc: 0.9916 - val_loss: 0.1122 - val_acc: 0.9660\n","Epoch 24/25\n","67743/67743 [==============================] - 16s 242us/step - loss: 0.0385 - acc: 0.9913 - val_loss: 0.0832 - val_acc: 0.9839\n","Epoch 25/25\n","67743/67743 [==============================] - 16s 241us/step - loss: 0.0395 - acc: 0.9913 - val_loss: 0.0746 - val_acc: 0.9868\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BLWpSe13CCf0","colab_type":"code","outputId":"e7c73555-cb47-46eb-be63-3627ce02375f","executionInfo":{"status":"ok","timestamp":1590275107553,"user_tz":-360,"elapsed":2886,"user":{"displayName":"Anonymous Learner","photoUrl":"","userId":"07578854066066276758"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["results = model.evaluate(X_test, y_test)\n","print(results)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["16524/16524 [==============================] - 2s 99us/step\n","[0.06512387010355214, 0.989348828792572]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hHJc50cWCbRi","colab_type":"code","colab":{}},"source":["y_pred=model.predict(X_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5oQu_gcGbLP_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"outputId":"6fbc832e-4bfb-4ccb-d353-b2c8a7cc1f7a","executionInfo":{"status":"ok","timestamp":1590275109368,"user_tz":-360,"elapsed":3500,"user":{"displayName":"Anonymous Learner","photoUrl":"","userId":"07578854066066276758"}}},"source":["\"\"\"\n","import numpy as np\n","array1=[[ 0,  1,  2,  3,  4],\n","       [ 0,  1,  2,  3,  4],\n","       [5, 6, 7, 1, 0],\n","       [5, 6, 7, 1, 0]]\n","array2=[[ 5, 6, 7, 1, 0],\n","       [ 0,  1,  2,  3,  4],\n","       [0,  1,  2,  3,  4],\n","       [5, 6, 7, 1, 0]]\n","\"\"\"\n","no_cat=len(y_test[0])\n","conf_mat=np.zeros(no_cat*no_cat).reshape(no_cat,no_cat)\n","test_size=len(y_test)\n","print(conf_mat.shape)\n","for i in range(test_size):\n","  y_t=y_test[i]\n","  y_p=y_pred[i]\n","  class_t=np.where(y_t == np.amax(y_t))\n","  class_t=class_t[0][0]\n","  class_p=np.where(y_p == np.amax(y_p))\n","  class_p=class_p[0][0]\n","  conf_mat[class_t][class_p]=conf_mat[class_t][class_p]+1"],"execution_count":28,"outputs":[{"output_type":"stream","text":["(8, 8)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DlLK_51IbR4R","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":67},"outputId":"464e75b2-954b-4500-9634-019c0cdf3121","executionInfo":{"status":"ok","timestamp":1590275109373,"user_tz":-360,"elapsed":2714,"user":{"displayName":"Anonymous Learner","photoUrl":"","userId":"07578854066066276758"}}},"source":["tp=np.zeros(no_cat)\n","fp=np.zeros(no_cat)\n","tn=np.zeros(no_cat)\n","fn=np.zeros(no_cat)\n","\n","prec=np.zeros(no_cat)\n","rec=np.zeros(no_cat)\n","f_score=np.zeros(no_cat)\n","\n","for i in range(no_cat):\n","  for j in range(no_cat):\n","    if i==j:\n","      tp[i]=conf_mat[i][j]\n","    if i!= j:\n","      fp[i] = fp[i]+conf_mat[j][i]\n","      fn[i] = fn[i]+conf_mat[i][j]\n","    for k in range(no_cat):\n","      if i!=k & j!=k:\n","        tn[i]=tn[i]+conf_mat[j][k]\n","\n","for i in range(no_cat):\n","    prec[i] = tp[i] * 100.0 / (tp[i] + fp[i])\n","    rec[i] = tp[i] * 100.0 / (tp[i] + fn[i])\n","    f_score[i] = 2 * prec[i] * rec[i] / (prec[i] + rec[i])\n","print(np.average(prec))\n","print(np.average(rec))\n","print(np.average(f_score))"],"execution_count":29,"outputs":[{"output_type":"stream","text":["98.88495402518008\n","98.93115207633198\n","98.9047963314457\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2OSOoS7Hs_TO","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}